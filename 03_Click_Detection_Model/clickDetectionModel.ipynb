{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click detection CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all libraries used in this notebook\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if GPU is available, if not use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import data and create the training, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting function for files and directories\n",
    "\n",
    "def sort_key_func(file_name):\n",
    "        numbers = re.findall(r'\\d+', file_name)\n",
    "        if numbers:\n",
    "            return int(numbers[0])\n",
    "        return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01_ethernet_without_additional_noise', '02_ethernet_with_additional_noise']\n"
     ]
    }
   ],
   "source": [
    "# import data from selected dataset\n",
    "\n",
    "cwd = str(Path.cwd())\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "audio_datasets_main_dir = \"01_Dataset/01_audioDatasets\"\n",
    "audio_datasets_main_dir = os.path.join(parent_dir, audio_datasets_main_dir)\n",
    "\n",
    "audio_datasets = []\n",
    "if os.path.exists(audio_datasets_main_dir):\n",
    "    for i in os.listdir(audio_datasets_main_dir):\n",
    "        #if folder name does not start with a dot\n",
    "        if i[0] != \".\": \n",
    "            audio_datasets.append(i)\n",
    "    audio_datasets.sort(key=sort_key_func)\n",
    "else:\n",
    "    print(\"Audio dataset directory does not exist\")\n",
    "\n",
    "print(audio_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spec_dataset_ethernet_wo_added_noise.npz']\n",
      "(128, 32)\n",
      "11144\n",
      "11144\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "dataset_num = 0\n",
    "\n",
    "dataset_dir = os.path.join(audio_datasets_main_dir, audio_datasets[dataset_num])\n",
    "\n",
    "# find files ending with .npz (stored numpy data) in the dataset_dir, if there is no such file in the direcori print there is noe npz file in the directory\n",
    "file_list = [f for f in os.listdir(dataset_dir) if f.endswith('.npz')]\n",
    "if len(file_list) == 0:\n",
    "    print(\"No npz file in the directory\")\n",
    "else:\n",
    "    print(file_list)\n",
    "    npz_file_num = 0\n",
    "\n",
    "    file_fullpath = os.path.join(dataset_dir, file_list[npz_file_num])\n",
    "\n",
    "    # check if the saved dataset can be loaded\n",
    "    data = np.load(file_fullpath)\n",
    "    loaded_spec_chunks = data['spec_chunks']\n",
    "    loaded_spec_chunk_labels = data['labels']\n",
    "\n",
    "    # check dataset information\n",
    "    print(loaded_spec_chunks[0].shape)\n",
    "    print(len(loaded_spec_chunks))\n",
    "    print(len(loaded_spec_chunk_labels))\n",
    "    # count the number of positive labels in numpy array\n",
    "    print(np.count_nonzero(loaded_spec_chunk_labels == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32)\n",
      "0.033793118 0.64435834\n"
     ]
    }
   ],
   "source": [
    "# normalize spectrogram chunks\n",
    "\n",
    "def normalize_spectrogram_chunks(spec_chunks):\n",
    "    # find global min and max values\n",
    "    global_min = np.min(spec_chunks)\n",
    "    global_max = np.max(spec_chunks)\n",
    "\n",
    "    normalized_spectrograms = [(spec - global_min) / (global_max - global_min) for spec in spec_chunks]\n",
    "\n",
    "    return normalized_spectrograms\n",
    "\n",
    "spec_chunks_norm = normalize_spectrogram_chunks(loaded_spec_chunks)\n",
    "\n",
    "print(spec_chunks_norm[0].shape)\n",
    "print(np.min(spec_chunks_norm[0]), np.max(spec_chunks_norm[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "10904\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into training, validation and test sets\n",
    "\n",
    "# separate positive and negative samples in spec_chunks_norm dataset based on the labels in loaded_spec_chunk_labels\n",
    "spec_chunks_norm_OK = []\n",
    "spec_chunks_norm_NOK = []\n",
    "for i, label in enumerate(loaded_spec_chunk_labels):\n",
    "    if label == 1:\n",
    "        spec_chunks_norm_OK.append(spec_chunks_norm[i])\n",
    "    else:\n",
    "        spec_chunks_norm_NOK.append(spec_chunks_norm[i])\n",
    "\n",
    "print(len(spec_chunks_norm_OK))\n",
    "print(len(spec_chunks_norm_NOK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clickSense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
