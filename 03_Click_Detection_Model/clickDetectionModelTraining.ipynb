{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSiDOnSybwKN"
   },
   "source": [
    "## Click detection CNN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 14698,
     "status": "ok",
     "timestamp": 1730141681994,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "o65eV1wpbwKU"
   },
   "outputs": [],
   "source": [
    "# all libraries used in this notebook\n",
    "import sys\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import platform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVfuJOePbwKX"
   },
   "source": [
    "This notebook is designed to run on both a local MacOS-based system and Google Colab to utilize the available computing power for model training.\n",
    "\n",
    "To run the notebook on Google Colab, the similar folder sctructure is required as for the local run with the subfolders and files for the datasets, model architecture, weights etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOgjULRPbwKY"
   },
   "source": [
    "### Directory structure\n",
    "Audio file dataset folders are in the subfolder \"01_audioDatasets/...\" <br>\n",
    "(\"01_audioDatasets\" folder is excluded from git, the relative path to this folder is in the gitignore file)<br>\n",
    "\n",
    "In case of new dataset --> new folder in \"01_Data/01_audioDatasets/\"\n",
    "\n",
    "```\n",
    "01_Electrical_Connector_Click-Event_Detection_git_repo/\n",
    "└─── 01_Dataset\n",
    "    └─── 01_audioDatasets (excluded from git)\n",
    "        ├─── 01_Ethernet\n",
    "        ├─── 02_Ethernet_test\n",
    "        ├─── ...\n",
    "        ├─── 07_Noise_samples\n",
    "        ├─── [New dataset folders go here]\n",
    "        \n",
    "    └─── preprocessNoiseAudio.ipynb\n",
    "    └─── ...\n",
    "└─── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1730141709543,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "bgSi6w2wbwKZ",
    "outputId": "a9a26bea-5b9e-419c-f7eb-9a2a458c0784"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Linux'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define op system\n",
    "system = platform.system()\n",
    "system\n",
    "\n",
    "# outputs: for MacOS: 'Darwin', for Linux: 'Linux'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUYy4Br9bwKa"
   },
   "source": [
    "### 1. Import data and create the training, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24114,
     "status": "ok",
     "timestamp": 1730141735700,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "AaklKUwJbwKb",
    "outputId": "a8dad5e9-3077-4a5f-d3eb-5bb2fd2c12b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/Masters_thesis_clickSense/01_Dataset/01_audioDatasets\n",
      "['01_Ethernet', '02_Ethernet_Test', '03_HVA280', '04_HVA280_Test', '05_HVA630', '06_HVA630_Test', '07_Noise_Samples']\n",
      "['01_Ethernet', '02_HVA280', '03_HVA630', '04_Noise_Samples']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# import data from selected dataset\n",
    "\n",
    "audio_datasets = []\n",
    "audio_datasets_augmented = []\n",
    "\n",
    "audio_datasets_main_dir_path = None\n",
    "audio_datasets_augemnted_dir_path = None\n",
    "local_system = True\n",
    "\n",
    "def access_data_from_local_system():\n",
    "    global audio_datasets_main_dir_path, audio_datasets_augemnted_dir_path\n",
    "    global audio_datasets, audio_datasets_augmented\n",
    "    cwd = str(Path.cwd())\n",
    "    parent_dir = os.path.dirname(cwd)\n",
    "    audio_datasets_main_dir = \"01_Dataset/01_audioDatasets\"\n",
    "    audio_datasets_main_dir_path = os.path.join(parent_dir, audio_datasets_main_dir)\n",
    "\n",
    "    audio_datasets_augemnted_dir = \"02_Data_Augmentation/01_augmentedDatasets\"\n",
    "    audio_datasets_augemnted_dir_path = os.path.join(parent_dir, audio_datasets_augemnted_dir)\n",
    "\n",
    "    if os.path.exists(audio_datasets_main_dir_path):\n",
    "        for i in os.listdir(audio_datasets_main_dir_path):\n",
    "            #if folder name does not start with a dot\n",
    "            if i[0] != \".\":\n",
    "                audio_datasets.append(i)\n",
    "        audio_datasets = sorted(audio_datasets)\n",
    "    else:\n",
    "        print(\"Audio dataset directory does not exist\")\n",
    "\n",
    "    if os.path.exists(audio_datasets_augemnted_dir_path):\n",
    "        for i in os.listdir(audio_datasets_augemnted_dir_path):\n",
    "            #if folder name does not start with a dot\n",
    "            if i[0] != \".\":\n",
    "                audio_datasets_augmented.append(i)\n",
    "        audio_datasets_augmented = sorted(audio_datasets_augmented)\n",
    "    else:\n",
    "        print(\"Augmented audio dataset directory does not exist\")\n",
    "\n",
    "    return audio_datasets, audio_datasets_augmented\n",
    "\n",
    "def access_data_from_google_colab():\n",
    "    global audio_datasets_main_dir_path, audio_datasets_augemnted_dir_path\n",
    "    global audio_datasets, audio_datasets_augmented\n",
    "    from google.colab import drive\n",
    "    # if drive not mounted\n",
    "    if not os.path.exists(\"/content/drive\"):\n",
    "        drive.mount(\"/content/drive\")\n",
    "    cwd = str(Path.cwd())\n",
    "    audio_datasets_main_dir_path = os.path.join(cwd, 'drive/MyDrive/Masters_thesis_clickSense/01_Dataset/01_audioDatasets')\n",
    "    audio_datasets_augemnted_dir_path = os.path.join(cwd, 'drive/MyDrive/Masters_thesis_clickSense/02_Data_Augmentation/01_augmentedDatasets')\n",
    "    print(audio_datasets_main_dir_path)\n",
    "\n",
    "    if os.path.exists(audio_datasets_main_dir_path):\n",
    "        for i in os.listdir(audio_datasets_main_dir_path):\n",
    "            #if folder name does not start with a dot\n",
    "            if i[0] != \".\":\n",
    "                audio_datasets.append(i)\n",
    "        audio_datasets = sorted(audio_datasets)\n",
    "    else:\n",
    "        print(\"Audio dataset directory does not exist\")\n",
    "\n",
    "    if os.path.exists(audio_datasets_augemnted_dir_path):\n",
    "        for i in os.listdir(audio_datasets_augemnted_dir_path):\n",
    "            #if folder name does not start with a dot\n",
    "            if i[0] != \".\":\n",
    "                audio_datasets_augmented.append(i)\n",
    "        audio_datasets_augmented = sorted(audio_datasets_augmented)\n",
    "    else:\n",
    "        print(\"Augmented audio dataset directory does not exist\")\n",
    "\n",
    "    return audio_datasets, audio_datasets_augmented\n",
    "\n",
    "if system == 'Darwin':\n",
    "    audio_datasets, audio_datasets_augmented = access_data_from_local_system()\n",
    "\n",
    "\n",
    " # google colab\n",
    "if system == \"Linux\":\n",
    "    try:\n",
    "        audio_datasets, audio_datasets_augmented = access_data_from_google_colab()\n",
    "        local_system = False\n",
    "    except:\n",
    "        print(\"Error accessing data from Google Colab\")\n",
    "        audio_datasets, audio_datasets_augmented = access_data_from_local_system()\n",
    "\n",
    "print(audio_datasets)\n",
    "print(audio_datasets_augmented)\n",
    "print(local_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20974,
     "status": "ok",
     "timestamp": 1730141758865,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "iUdrwFz_bwKb",
    "outputId": "763a49c3-e3d8-4127-cbbf-91b7d687062f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: [0, 6]\n",
      "augmented datasets: [0, 3]\n",
      "['ethernet_dataset.npz']\n",
      "['noise_dataset.npz']\n",
      "['ethernet_dataset_augmented_w_generated_noise.npz', 'ethernet_dataset_augmented_w_recorded_noise.npz']\n",
      "['noise_dataset_generated.npz']\n",
      "(128, 32)\n",
      "number of spectrogram chunks: 22220\n",
      "positive samples: 5778\n",
      "negative samples: 16442\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "datasets_augmented = []\n",
    "\n",
    "dataset_id = 0 # ID of the selected datasets, 0 - ethernet, 2 - hva 280, 4 - hva 630\n",
    "\n",
    "if dataset_id == 0:\n",
    "    dataset_augmented_id = 0\n",
    "elif dataset_id == 2:\n",
    "    dataset_augmented_id = 1\n",
    "elif dataset_id == 4:\n",
    "    dataset_augmented_id = 2\n",
    "\n",
    "long_window = False\n",
    "if dataset_id == 2:\n",
    "    long_window = True\n",
    "\n",
    "noise_dataset_id = 6\n",
    "noise_dataset_augmented_id = 3\n",
    "\n",
    "datasets.append(dataset_id)\n",
    "datasets.append(noise_dataset_id)\n",
    "\n",
    "datasets_augmented.append(dataset_augmented_id)\n",
    "datasets_augmented.append(noise_dataset_augmented_id)\n",
    "\n",
    "print(f\"datasets: {datasets}\")\n",
    "print(f\"augmented datasets: {datasets_augmented}\")\n",
    "\n",
    "loaded_spec_chunks = None\n",
    "loaded_spec_chunk_labels = None\n",
    "\n",
    "\n",
    "\n",
    "for i in datasets:\n",
    "    dataset_dir_path = os.path.join(audio_datasets_main_dir_path, audio_datasets[i])\n",
    "    file_list = []\n",
    "\n",
    "    for f in os.listdir(dataset_dir_path):\n",
    "        if i == 6 and f.endswith('.npz'):\n",
    "            if long_window and \"long\" in f:\n",
    "                file_list.append(f)\n",
    "            elif not long_window and \"long\" not in f:\n",
    "                file_list.append(f)\n",
    "        elif f.endswith('.npz'):\n",
    "            file_list.append(f)\n",
    "\n",
    "    print(file_list)\n",
    "\n",
    "    if len(file_list) == 0:\n",
    "        print(f\"No npz file in the directory {audio_datasets[i]}\")\n",
    "    else:\n",
    "        for file in file_list:\n",
    "            file_fullpath = os.path.join(dataset_dir_path, file)\n",
    "\n",
    "            data = np.load(file_fullpath)\n",
    "\n",
    "            if loaded_spec_chunks is None:\n",
    "                loaded_spec_chunks = data['spec_chunks']\n",
    "                loaded_spec_chunk_labels = data['labels']\n",
    "            else:\n",
    "                loaded_spec_chunks = np.concatenate((loaded_spec_chunks, data['spec_chunks']), axis=0)\n",
    "                loaded_spec_chunk_labels = np.concatenate((loaded_spec_chunk_labels, data['labels']), axis=0)\n",
    "\n",
    "for i in datasets_augmented:\n",
    "    dataset_augmented_dir_path = os.path.join(audio_datasets_augemnted_dir_path, audio_datasets_augmented[i])\n",
    "    file_list = []\n",
    "\n",
    "    for f in os.listdir(dataset_augmented_dir_path):\n",
    "        if i == 3 and f.endswith('.npz'):\n",
    "            if long_window and \"long\" in f:\n",
    "                file_list.append(f)\n",
    "            elif not long_window and \"long\" not in f:\n",
    "                file_list.append(f)\n",
    "        elif f.endswith('.npz'):\n",
    "            file_list.append(f)\n",
    "\n",
    "    print(file_list)\n",
    "    if len(file_list) == 0:\n",
    "        print(f\"No npz file in the directory {audio_datasets_augmented[i]}\")\n",
    "    else:\n",
    "        for file in file_list:\n",
    "            file_fullpath = os.path.join(dataset_augmented_dir_path, file)\n",
    "\n",
    "            data = np.load(file_fullpath)\n",
    "\n",
    "            if loaded_spec_chunks is None:\n",
    "                loaded_spec_chunks = data['spec_chunks']\n",
    "                loaded_spec_chunk_labels = data['labels']\n",
    "            else:\n",
    "                loaded_spec_chunks = np.concatenate((loaded_spec_chunks, data['spec_chunks']), axis=0)\n",
    "                loaded_spec_chunk_labels = np.concatenate((loaded_spec_chunk_labels, data['labels']), axis=0)\n",
    "\n",
    "# check dataset information\n",
    "print(loaded_spec_chunks[0].shape)\n",
    "print(f\"number of spectrogram chunks: {len(loaded_spec_chunks)}\")\n",
    "\n",
    "# check number of 1s and 0s in the labels\n",
    "print(f\"positive samples: {np.count_nonzero(loaded_spec_chunk_labels == 1)}\")\n",
    "print(f\"negative samples: {np.count_nonzero(loaded_spec_chunk_labels == 0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1730141760924,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "IAvPJNig06Be",
    "outputId": "fc11f221-d16f-4eed-8cd1-549f66c9c1ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'# balance the dataset\\n\\npositive_indices = np.where(loaded_spec_chunk_labels == 1)[0]\\nnegative_indices = np.where(loaded_spec_chunk_labels == 0)[0]\\n\\nnum_positive = len(positive_indices)\\nnum_negative = len(negative_indices)\\n\\nprint(f\"Positive samples: {num_positive}\")\\nprint(f\"Negative samples: {num_negative}\")\\n\\nnp.random.seed(42)\\n\\nif num_negative > num_positive:\\n    downsampled_negative_indices = np.random.choice(negative_indices, size=num_positive, replace=False)\\nelse:\\n    downsampled_negative_indices = negative_indices\\n\\nbalanced_indices = np.concatenate([positive_indices, downsampled_negative_indices])\\n\\nbalanced_spec_chunks = loaded_spec_chunks[balanced_indices]\\nbalanced_spec_chunk_labels = loaded_spec_chunk_labels[balanced_indices]\\n\\n\\n\\nprint(f\"Number of spectrogram chunks after balancing: {len(balanced_spec_chunks)}\")\\nprint(f\"Positive samples: {np.count_nonzero(balanced_spec_chunk_labels == 1)}\")\\nprint(f\"Negative samples: {np.count_nonzero(balanced_spec_chunk_labels == 0)}\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# balance the dataset\n",
    "\n",
    "positive_indices = np.where(loaded_spec_chunk_labels == 1)[0]\n",
    "negative_indices = np.where(loaded_spec_chunk_labels == 0)[0]\n",
    "\n",
    "num_positive = len(positive_indices)\n",
    "num_negative = len(negative_indices)\n",
    "\n",
    "print(f\"Positive samples: {num_positive}\")\n",
    "print(f\"Negative samples: {num_negative}\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "if num_negative > num_positive:\n",
    "    downsampled_negative_indices = np.random.choice(negative_indices, size=num_positive, replace=False)\n",
    "else:\n",
    "    downsampled_negative_indices = negative_indices\n",
    "\n",
    "balanced_indices = np.concatenate([positive_indices, downsampled_negative_indices])\n",
    "\n",
    "balanced_spec_chunks = loaded_spec_chunks[balanced_indices]\n",
    "balanced_spec_chunk_labels = loaded_spec_chunk_labels[balanced_indices]\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Number of spectrogram chunks after balancing: {len(balanced_spec_chunks)}\")\n",
    "print(f\"Positive samples: {np.count_nonzero(balanced_spec_chunk_labels == 1)}\")\n",
    "print(f\"Negative samples: {np.count_nonzero(balanced_spec_chunk_labels == 0)}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1730141762530,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "4HoHw2oebwKc",
    "outputId": "7686e9d9-2c4d-4016-be27-744f54f39b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-120 0\n",
      "(128, 32)\n",
      "0.0438104 0.59884274\n"
     ]
    }
   ],
   "source": [
    "# normalize spectrogram chunks\n",
    "\n",
    "## update with the decibel scale min max used in real time detection!!!\n",
    "\n",
    "def normalize_spectrogram_chunks(spec_chunks):\n",
    "    # find global min and max values\n",
    "    \"\"\"global_min = np.min(spec_chunks)\n",
    "    global_max = np.max(spec_chunks)\"\"\"\n",
    "\n",
    "    # min and max dB values set in the preprocessing notebook\n",
    "    global_min = -120\n",
    "    global_max = 0\n",
    "\n",
    "    print(global_min, global_max)\n",
    "\n",
    "    normalized_spectrograms = [(spec - global_min) / (global_max - global_min) for spec in spec_chunks]\n",
    "\n",
    "    return normalized_spectrograms\n",
    "\n",
    "#balanced_spec_chunks_norm = normalize_spectrogram_chunks(balanced_spec_chunks)\n",
    "\n",
    "spec_chunks_norm = normalize_spectrogram_chunks(loaded_spec_chunks)\n",
    "\n",
    "print(spec_chunks_norm[0].shape)\n",
    "print(np.min(spec_chunks_norm[0]), np.max(spec_chunks_norm[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1730141764121,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "P6nSO7SnbwKd",
    "outputId": "38f3cc1f-f86c-4cd3-a3e3-d5b49d6a0718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         spectrogram  label\n",
      "0  [[0.3788925, 0.25929248, 0.26714045, 0.3332723...    0.0\n",
      "1  [[0.13239302, 0.16194344, 0.07906348, 0.094020...    0.0\n",
      "2  [[0.16781941, 0.070345685, 0.15296523, 0.19073...    0.0\n",
      "3  [[0.13016383, 0.12481639, 0.16004111, 0.209296...    0.0\n",
      "4  [[0.1644024, 0.13420811, 0.13773626, 0.0968164...    0.0\n",
      "                                           spectrogram  label\n",
      "176  [[0.20453428, 0.19660683, 0.1803208, 0.2099158...    1.0\n",
      "177  [[0.21733004, 0.14077899, 0.14537048, 0.109780...    1.0\n",
      "178  [[0.16921425, 0.047691345, 0.13245894, 0.14110...    1.0\n",
      "179  [[0.1505352, 0.1640859, 0.11732661, 0.08867721...    1.0\n",
      "420  [[0.1319903, 0.1413681, 0.1483827, 0.11101411,...    1.0\n",
      "Train set size: 17775, Validation set size: 2222, Test set size: 2223\n",
      "label\n",
      "0.0    13153\n",
      "1.0     4622\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0.0    1644\n",
      "1.0     578\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0.0    1645\n",
      "1.0     578\n",
      "Name: count, dtype: int64\n",
      "                                             spectrogram  label\n",
      "14740  [[0.24702454, 0.18861097, 0.22347984, 0.252399...    1.0\n",
      "18158  [[0.14289208, 0.17599843, 0.32905, 0.5136591, ...    1.0\n",
      "2453   [[0.1604894, 0.1235911, 0.16218573, 0.05922985...    1.0\n",
      "17456  [[0.14579722, 0.13268846, 0.1678997, 0.1997109...    1.0\n",
      "16774  [[0.17666067, 0.16979803, 0.111344084, 0.14602...    1.0\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into training, validation and test sets\n",
    "\n",
    "# create a dataframe to store the spectrogram chunks and their labels\n",
    "df_spectrogram_dataset = pd.DataFrame(columns=['spectrogram', 'label'])\n",
    "\n",
    "# add the spectrogram chunks and their labels to the dataframe\n",
    "df_spectrogram_dataset['spectrogram'] = spec_chunks_norm\n",
    "df_spectrogram_dataset['label'] = loaded_spec_chunk_labels\n",
    "\n",
    "# in case of using the balanced dataset\n",
    "# df_spectrogram_dataset['label'] = balanced_spec_chunk_labels\n",
    "\n",
    "print(df_spectrogram_dataset.head())\n",
    "print(df_spectrogram_dataset[df_spectrogram_dataset.label == 1].head())\n",
    "\n",
    "# separate positive and negative samples in spec_chunks_norm dataset based on the labels in loaded_spec_chunk_labels\n",
    "spec_chunks_OK = df_spectrogram_dataset[df_spectrogram_dataset['label'] == 1]\n",
    "spec_chunks_NOK = df_spectrogram_dataset[df_spectrogram_dataset['label'] == 0]\n",
    "\n",
    "# Function to split a dataframe according to the 60-20-20 ratio\n",
    "def split_df(df):\n",
    "    train, temp = train_test_split(df, test_size=0.2, random_state=42)  # test_size = 0.2 --> 80% for training, 20% for validation and testing\n",
    "    val, test = train_test_split(temp, test_size=0.5, random_state=42)  # 10% for validation, 10% for testing\n",
    "    return train, val, test\n",
    "\n",
    "train_OK, val_OK, test_OK = split_df(spec_chunks_OK)\n",
    "train_NOK, val_NOK, test_NOK = split_df(spec_chunks_NOK)\n",
    "\n",
    "# Combine the corresponding sets\n",
    "train_set = pd.concat([train_OK, train_NOK]).sample(frac=1, random_state=42)\n",
    "val_set = pd.concat([val_OK, val_NOK]).sample(frac=1, random_state=42)\n",
    "test_set = pd.concat([test_OK, test_NOK]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(f\"Train set size: {len(train_set)}, Validation set size: {len(val_set)}, Test set size: {len(test_set)}\")\n",
    "print(train_set.label.value_counts())\n",
    "print(val_set.label.value_counts())\n",
    "print(test_set.label.value_counts())\n",
    "print(train_set[train_set.label == 1].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1730141765813,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "lDrxz8bGbwKe",
    "outputId": "ab448d9d-144e-4ee1-fb3a-b1a8b1f9f8db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (17775, 128, 32)\n",
      "train targets shape: (17775,)\n",
      "val data shape: (2222, 128, 32)\n",
      "val targets shape: (2222,)\n",
      "test data shape: (2223, 128, 32)\n",
      "test targets shape: (2223,) \n",
      "\n",
      "torch.Size([17775, 1, 128, 32]) torch.Size([17775])\n",
      "torch.Size([2222, 1, 128, 32]) torch.Size([2222])\n",
      "torch.Size([2223, 1, 128, 32]) torch.Size([2223])\n"
     ]
    }
   ],
   "source": [
    "# prepare data for model input --> convert to torch sensors\n",
    "\n",
    "def prepare_data(df):\n",
    "    X = np.stack(df['spectrogram'].values)  # convert spectrogram list to numpy array\n",
    "    #X = np.expand_dims(X, axis=1)  # add channel dimension\n",
    "    y = df['label'].values\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = prepare_data(train_set)\n",
    "X_val, y_val = prepare_data(val_set)\n",
    "X_test, y_test = prepare_data(test_set)\n",
    "\n",
    "print(\"train data shape:\", X_train.shape)\n",
    "print(\"train targets shape:\", y_train.shape)\n",
    "print(\"val data shape:\", X_val.shape)\n",
    "print(\"val targets shape:\", y_val.shape)\n",
    "print(\"test data shape:\", X_test.shape)\n",
    "print(\"test targets shape:\", y_test.shape, '\\n')\n",
    "\n",
    "# convert to torch tensors\n",
    "def to_tensor(X, y):\n",
    "    X = torch.from_numpy(X).type(torch.float32).unsqueeze(1) # convert to torch and add channel dimension\n",
    "    y = torch.from_numpy(y).type(torch.float32)\n",
    "    return X, y\n",
    "\n",
    "X_train_tens, y_train_tens = to_tensor(X_train, y_train)\n",
    "X_val_tens, y_val_tens = to_tensor(X_val, y_val)\n",
    "X_test_tens, y_test_tens = to_tensor(X_test, y_test)\n",
    "\n",
    "# View the first five samples\n",
    "print(X_train_tens.shape, y_train_tens.shape)\n",
    "print(X_val_tens.shape, y_val_tens.shape)\n",
    "print(X_test_tens.shape, y_test_tens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1730141767268,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "cdHBr1dTbwKf",
    "outputId": "9b7b9115-a331-42fb-f1c1-a82c3e5d0876"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if GPU is available, if not use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 673,
     "status": "ok",
     "timestamp": 1730141769106,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "h1w2CT8DbwKf",
    "outputId": "15ac37e5-53ee-4c13-ffee-d7c84c5adbcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataloader: 1111\n",
      "Length of test dataloader: 139\n",
      "Length of test dataloader: 139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 128, 32]), torch.Size([16]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataloaders for training, validation and test sets\n",
    "\n",
    "if long_window:\n",
    "  BATCH_SIZE = 16\n",
    "else:\n",
    "  BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tens, y_train_tens)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val_tens, y_val_tens)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_tens, y_test_tens)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"Length of train dataloader: {len(train_loader)}\")\n",
    "print(f\"Length of test dataloader: {len(val_loader)}\")\n",
    "print(f\"Length of test dataloader: {len(test_loader)}\")\n",
    "\n",
    "train_features_batch, train_labels_batch = next(iter(train_loader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1730141770461,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "b1H1jtSgbwKg",
    "outputId": "65a315e3-10ac-4fa7-d27b-aa07fdfa0bb5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nif not long_window:\\n  selected_model = \"ClickDetectorCNN_v1.py\"\\nelif long_window:\\n  selected_model = \"ClickDetectorCNN_v1_long_window.py\"\\n\\n#module = importlib.import_module(architecture_file[:-3])\\n\\ncwd = str(Path.cwd())\\nif system == \\'Darwin\\':\\n  model_architectures_dir = \"01_modelArchitectures\"\\nelif system == \\'Linux\\':\\n  model_architectures_dir = \"drive/MyDrive/Masters_thesis_clickSense/03_Click_Detection_Model/01_modelArchitectures\"\\nmodel_architectures_dir_path = os.path.join(cwd, model_architectures_dir)\\nprint(model_architectures_dir_path)\\nif os.path.exists(model_architectures_dir_path):\\n    sys.path.append(model_architectures_dir_path)\\n    model_module = importlib.import_module(selected_model[:-3])\\n    #from ClickDetectorCNN_v1 import ClickDetectorCNN\\n    ClickDetectorCNN = getattr(model_module, \\'ClickDetectorCNN\\') #access the ClickDetectorCNN class\\n    model = ClickDetectorCNN(input_channels=1, output_shape=1).to(device)\\nelse:\\n    print(\"Model architectures directory does not exist\")\\n\\nmodel = ClickDetectorCNN(input_channels=1, output_shape=1).to(device)\\nmodel\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model architecture\n",
    "\"\"\"\n",
    "if not long_window:\n",
    "  selected_model = \"ClickDetectorCNN_v1.py\"\n",
    "elif long_window:\n",
    "  selected_model = \"ClickDetectorCNN_v1_long_window.py\"\n",
    "\n",
    "#module = importlib.import_module(architecture_file[:-3])\n",
    "\n",
    "cwd = str(Path.cwd())\n",
    "if system == 'Darwin':\n",
    "  model_architectures_dir = \"01_modelArchitectures\"\n",
    "elif system == 'Linux':\n",
    "  model_architectures_dir = \"drive/MyDrive/Masters_thesis_clickSense/03_Click_Detection_Model/01_modelArchitectures\"\n",
    "model_architectures_dir_path = os.path.join(cwd, model_architectures_dir)\n",
    "print(model_architectures_dir_path)\n",
    "if os.path.exists(model_architectures_dir_path):\n",
    "    sys.path.append(model_architectures_dir_path)\n",
    "    model_module = importlib.import_module(selected_model[:-3])\n",
    "    #from ClickDetectorCNN_v1 import ClickDetectorCNN\n",
    "    ClickDetectorCNN = getattr(model_module, 'ClickDetectorCNN') #access the ClickDetectorCNN class\n",
    "    model = ClickDetectorCNN(input_channels=1, output_shape=1).to(device)\n",
    "else:\n",
    "    print(\"Model architectures directory does not exist\")\n",
    "\n",
    "model = ClickDetectorCNN(input_channels=1, output_shape=1).to(device)\n",
    "model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1730141771743,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "OeGB8Y0EkBEb",
    "outputId": "4087b039-bbab-4a2e-98c3-fde8270272fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClickDetectorCNN(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=16384, out_features=1, bias=True)\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model architecture for hyperparameter optimization\n",
    "\n",
    "class ClickDetectorCNN(nn.Module):\n",
    "    def __init__(self, input_channels, output_shape, input_width, input_height, ch1, ch2, kernel_size_1, stride_1, kernel_size_2, stride_2, padding):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channels,\n",
    "                      out_channels=ch1,\n",
    "                      kernel_size=kernel_size_1,\n",
    "                      stride=stride_1,\n",
    "                      padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=kernel_size_2, stride=stride_2)\n",
    "        )\n",
    "        output_width_1 = (input_width - kernel_size_2) // stride_2 + 1\n",
    "        output_height_1 = (input_height - kernel_size_2) // stride_2 + 1\n",
    "\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=ch1,\n",
    "                      out_channels=ch2,\n",
    "                      kernel_size=kernel_size_1,\n",
    "                      stride=stride_1,\n",
    "                      padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=kernel_size_2, stride=stride_2)\n",
    "\n",
    "        )\n",
    "        output_width_2 = (output_width_1 - kernel_size_2) // stride_2 + 1\n",
    "        output_height_2 = (output_height_1 - kernel_size_2) // stride_2 + 1\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features= ch2 * output_width_2 * output_height_2, ## ch x w x h\n",
    "                      out_features=output_shape),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "input_height = X_train_tens.shape[2]\n",
    "input_width = X_train_tens.shape[3]\n",
    "print(input_height, input_width)\n",
    "\n",
    "ch1 = [32, 64, 128]\n",
    "ch2 = [32, 64, 128]\n",
    "\n",
    "model = ClickDetectorCNN(input_channels=1, output_shape=1, input_width=input_width, input_height=input_height, ch1=ch1[1], ch2=ch2[1], kernel_size_1=3, stride_1=1, kernel_size_2=2, stride_2=2, padding=\"same\")\n",
    "\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 882,
     "referenced_widgets": [
      "50691ce548d945a0861e34543806595e",
      "53eecbecb7d74bb08fbd26a13d2039a8",
      "f1e855ac80a54fd3bb932daeff22a824",
      "fd7e8de4a8ec4a54bd8dccb087585df1",
      "cf4a2e8addf94787b6a90d7afaab92ab",
      "58e5b7754d35431a96eef108f38f524a",
      "583588cc9b384f35a48f2928835940c1",
      "483936814556495094d617bdc33d2b6f",
      "e84ee5d377104ce7ac52341ebaf1866b",
      "7b56246ce756499bbd82393aa8323f3b",
      "65222142ffde4598b27256090659c53d"
     ]
    },
    "executionInfo": {
     "elapsed": 122057,
     "status": "ok",
     "timestamp": 1730144148184,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "i9A6jbgxbwKh",
    "outputId": "f1b64206-8751-4e10-a4c9-47142360a2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch1: 32, ch2: 128, learning rate: 0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50691ce548d945a0861e34543806595e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.19153 | Train accuracy: 91.48%\n",
      "Validation loss: 0.07121 | Validation accuracy: 97.71%\n",
      "\n",
      "Train loss: 0.05266 | Train accuracy: 98.24%\n",
      "Validation loss: 0.04200 | Validation accuracy: 98.43%\n",
      "\n",
      "Train loss: 0.02910 | Train accuracy: 99.15%\n",
      "Validation loss: 0.02734 | Validation accuracy: 99.06%\n",
      "\n",
      "Train loss: 0.02223 | Train accuracy: 99.31%\n",
      "Validation loss: 0.02343 | Validation accuracy: 99.19%\n",
      "\n",
      "Train loss: 0.01588 | Train accuracy: 99.54%\n",
      "Validation loss: 0.03424 | Validation accuracy: 98.74%\n",
      "\n",
      "Train loss: 0.01372 | Train accuracy: 99.59%\n",
      "Validation loss: 0.00713 | Validation accuracy: 99.73%\n",
      "\n",
      "Train loss: 0.01492 | Train accuracy: 99.51%\n",
      "Validation loss: 0.01054 | Validation accuracy: 99.64%\n",
      "\n",
      "Train loss: 0.01035 | Train accuracy: 99.62%\n",
      "Validation loss: 0.00953 | Validation accuracy: 99.69%\n",
      "\n",
      "Train loss: 0.00856 | Train accuracy: 99.71%\n",
      "Validation loss: 0.00660 | Validation accuracy: 99.78%\n",
      "\n",
      "Train loss: 0.00736 | Train accuracy: 99.74%\n",
      "Validation loss: 0.00616 | Validation accuracy: 99.82%\n",
      "\n",
      "Train loss: 0.00921 | Train accuracy: 99.73%\n",
      "Validation loss: 0.02186 | Validation accuracy: 99.19%\n",
      "\n",
      "Train loss: 0.00655 | Train accuracy: 99.80%\n",
      "Validation loss: 0.00902 | Validation accuracy: 99.78%\n",
      "\n",
      "Train loss: 0.00574 | Train accuracy: 99.81%\n",
      "Validation loss: 0.01184 | Validation accuracy: 99.55%\n",
      "\n",
      "Train loss: 0.00495 | Train accuracy: 99.87%\n",
      "Validation loss: 0.00924 | Validation accuracy: 99.69%\n",
      "\n",
      "Train loss: 0.00207 | Train accuracy: 99.93%\n",
      "Validation loss: 0.01126 | Validation accuracy: 99.46%\n",
      "\n",
      "Early stopping triggered at epoch 14\n",
      "Current best training parameters: [32, 128, 0.001]\n",
      "Best model parameters: [32, 128, 0.001]\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "\n",
    "# initialize best model parameters\n",
    "best_model_weights_all = None\n",
    "best_val_loss_all = float('inf')\n",
    "best_training_params = [] # ch1, ch2, learning_rate\n",
    "train_losses_best, val_losses_best = [], []\n",
    "\n",
    "# hyperparameters for optimization\n",
    "## kernel chanel sizes\n",
    "#channels_1 = [32, 64, 128]\n",
    "#channels_2 = [32, 64, 128]\n",
    "\n",
    "channels_1 = [32]\n",
    "channels_2 = [128]\n",
    "\n",
    "## learning rates\n",
    "#learning_rates = [1e-2, 1e-3, 1e-4] # -> 0.01, 0.001, 0.0001\n",
    "learning_rates = [1e-3]\n",
    "\n",
    "binary_threshold = 0.5 # for prediction -> also use in real time detection\n",
    "\n",
    "loss_fn = nn.BCELoss() # Binary Cross Entropy Loss\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "# early stopping parameters\n",
    "patience = 5  # epochs to wait after last time validation loss improved\n",
    "delta = 0.001  # minimum change in the validation loss\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "        binary_predictions = (y_pred > binary_threshold).float()\n",
    "        correct = torch.eq(y_true, binary_predictions).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "        acc = (correct / len(y_pred)) * 100\n",
    "        return acc\n",
    "\n",
    "def initialize_model_and_optimizer(ch1, ch2, learning_rate):\n",
    "        global model, optimizer\n",
    "        model = ClickDetectorCNN(input_channels=1,\n",
    "                                 output_shape=1,\n",
    "                                 input_width=input_width,\n",
    "                                 input_height=input_height,\n",
    "                                 ch1=ch1, ch2=ch2,\n",
    "                                 kernel_size_1=3,\n",
    "                                 stride_1=1, kernel_size_2=2,\n",
    "                                 stride_2=2,\n",
    "                                 padding=\"same\").to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        return model, optimizer\n",
    "\n",
    "# model training with hyperparameters optimization\n",
    "def model_training(ch1, ch2, learning_rate):\n",
    "\n",
    "    global best_val_loss_all, best_model_weights_all, best_training_params\n",
    "    global train_losses_best, val_losses_best\n",
    "\n",
    "    best_model_weights = None\n",
    "    best_val_loss = float('inf')  # initialize best validation loss as infinity\n",
    "    best_val_acc = 0 # initialize best validation accuracy\n",
    "    patience_counter = 0  # counter for epochs since last improvement\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    #initialize the model and optimizer\n",
    "    model, optimizer = initialize_model_and_optimizer(ch1, ch2, learning_rate)\n",
    "\n",
    "    def train_step(model: torch.nn.Module,\n",
    "                data_loader: torch.utils.data.DataLoader,\n",
    "                loss_fn: torch.nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                accuracy_fn,\n",
    "                device: torch.device = device):\n",
    "\n",
    "        train_loss, train_acc = 0, 0\n",
    "\n",
    "        #model.to(device)\n",
    "        #for batch, (X, y) in enumerate(data_loader):\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            # forward pass\n",
    "            y_pred = model(X)\n",
    "\n",
    "            y_pred = torch.squeeze(y_pred) # from shape [batch_size, 1] -> [batch_size]\n",
    "\n",
    "            # calculate loss per batch\n",
    "            loss = loss_fn(y_pred, y.float())\n",
    "            train_loss += loss # accumulatively add up the loss\n",
    "            train_acc += accuracy_fn(y_true=y, y_pred=y_pred)\n",
    "\n",
    "            #optimizer.zero_grad()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # loss backward\n",
    "            loss.backward()\n",
    "\n",
    "            # optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # average loss per batch per epoch\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(data_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def validation_step(model: torch.nn.Module,\n",
    "                        data_loader: torch.utils.data.DataLoader,\n",
    "                        loss_fn: torch.nn.Module,\n",
    "                        accuracy_fn,\n",
    "                        device: torch.device = device):\n",
    "\n",
    "        val_loss, val_acc = 0, 0\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for X, y in val_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                val_pred = model(X)\n",
    "                val_pred = torch.squeeze(val_pred)\n",
    "                val_loss += loss_fn(val_pred, y.float()).detach() # accumulatively add up the loss per epoch\n",
    "                #val_acc += accuracy_fn(y_true=y, y_pred=val_pred.argmax(dim=1))\n",
    "                val_acc += accuracy_fn(y_true=y, y_pred=val_pred)\n",
    "\n",
    "                del X, y, val_pred\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            val_acc /= len(data_loader)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Validation loss: {val_loss:.5f} | Validation accuracy: {val_acc:.2f}%\\n\")\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        #print(f\"Epoch: {epoch}\\n---------\")\n",
    "        train_step(data_loader=train_loader,\n",
    "            model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            accuracy_fn=accuracy_fn\n",
    "        )\n",
    "\n",
    "        val_loss = validation_step(data_loader=val_loader,\n",
    "            model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            accuracy_fn=accuracy_fn\n",
    "        )\n",
    "\n",
    "        # early stopping if there is no improvement in the validation loss\n",
    "        if epoch == 0 or (epoch > 0 and val_loss < val_losses[-2]):\n",
    "\n",
    "          # update best val loss for the epoch\n",
    "          if val_loss < best_val_loss:\n",
    "              best_val_loss = val_loss\n",
    "\n",
    "              patience_counter = 0  # reset counter\n",
    "\n",
    "              # updating all time best in case of a better val loss\n",
    "              if best_val_loss < best_val_loss_all:\n",
    "                  best_val_loss_all = best_val_loss\n",
    "                  best_model_weights_all = model.state_dict().copy()\n",
    "                  best_training_params = [ch1, ch2, learning_rate]\n",
    "          else:\n",
    "            patience_counter += 1  # increment counter\n",
    "            #print(f\"No improvement in validation loss for {patience_counter} epochs\")\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "\n",
    "                break\n",
    "\n",
    "\n",
    "        else:\n",
    "            patience_counter += 1  # increment counter\n",
    "            #print(f\"No improvement in validation loss for {patience_counter} epochs\")\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "\n",
    "                break\n",
    "\n",
    "        ## store the learning curves of the best model\n",
    "        if min(val_losses) <= best_val_loss_all:\n",
    "            train_losses_best = train_losses.copy()\n",
    "            val_losses_best = val_losses.copy()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    del model, optimizer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return best_model_weights_all, best_training_params, train_losses_best, val_losses_best\n",
    "\n",
    "\n",
    "# hyperparameter optimization\n",
    "for lr in learning_rates:\n",
    "    for ch1 in channels_1:\n",
    "        for ch2 in channels_2:\n",
    "            if ch2 >= ch1:\n",
    "                print(f\"ch1: {ch1}, ch2: {ch2}, learning rate: {lr}\")\n",
    "                best_model_weights, best_training_params, train_losses_best, val_losses_best = model_training(ch1, ch2, lr)\n",
    "                print(f\"Current best training parameters: {best_training_params}\")\n",
    "                # Clear memory after each run\n",
    "                torch.cuda.empty_cache()\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(f\"Best model parameters: {best_training_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1170,
     "status": "ok",
     "timestamp": 1730144195177,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "BrIzqBpYbwKi",
    "outputId": "07ac1cc2-6f09-44b6-d1bb-024e295a8c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 99.51%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the test set\n",
    "# variables for accumulatively adding up loss and accuracy\n",
    "test_loss, test_acc = 0, 0\n",
    "\n",
    "all_preds = []\n",
    "all_true_labels = []\n",
    "\n",
    "# initialize the model with channel sizes from the best traing params\n",
    "model = ClickDetectorCNN(input_channels=1, output_shape=1, input_width=input_width, input_height=input_height, ch1=best_training_params[0], ch2=best_training_params[1], kernel_size_1=3, stride_1=1, kernel_size_2=2, stride_2=2, padding=\"same\").to(device)\n",
    "model.load_state_dict(best_model_weights_all)\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in test_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # forward pass\n",
    "        test_pred = model(X)\n",
    "        test_pred = torch.squeeze(test_pred)\n",
    "\n",
    "        # calculate loss accumatively\n",
    "        test_loss += loss_fn(test_pred, y.float()) # accumulatively add up the loss per epoch\n",
    "\n",
    "        # calculate accuracy\n",
    "        binary_predictions = (test_pred > binary_threshold).float()\n",
    "\n",
    "        test_acc += accuracy_fn(y_true=y, y_pred=test_pred)\n",
    "\n",
    "        all_preds.extend(binary_predictions.tolist())\n",
    "        all_true_labels.extend(y.tolist())\n",
    "\n",
    "    # divide total test loss by length of test dataloader (per batch)\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    # divide total accuracy by length of test dataloader (per batch)\n",
    "    test_acc /= len(test_loader)\n",
    "\n",
    "print(f\"Test acc: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1730144196775,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "yZ_QB3h5bwKi",
    "outputId": "7ebe0056-8b47-46ee-c2b5-c3c6c455f2aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 236.22x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot out confusion matrix\n",
    "\n",
    "width_cm = 6\n",
    "height_cm = 6\n",
    "cm_to_inch = 2.54\n",
    "\n",
    "fig_cm, ax_cm = plt.subplots(figsize=(width_cm/cm_to_inch, height_cm/cm_to_inch))\n",
    "\n",
    "cm = confusion_matrix(all_true_labels, all_preds)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot(ax=ax_cm, cmap = None, colorbar=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1730144198889,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "rZrbdfV9bwKj",
    "outputId": "d85a17a3-e345-4945-88bc-fc44a7e807da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[tensor(0.0712, device='cuda:0'), tensor(0.0420, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0234, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0071, device='cuda:0'), tensor(0.0105, device='cuda:0'), tensor(0.0095, device='cuda:0'), tensor(0.0066, device='cuda:0'), tensor(0.0062, device='cuda:0'), tensor(0.0219, device='cuda:0'), tensor(0.0090, device='cuda:0'), tensor(0.0118, device='cuda:0'), tensor(0.0092, device='cuda:0')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 393.701x236.22 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print learning curves\n",
    "\n",
    "print(len(train_losses_best))\n",
    "print(val_losses_best)\n",
    "\n",
    "train_loss_values = [loss.item() for loss in train_losses_best]\n",
    "val_loss_values = [loss.item() for loss in val_losses_best]\n",
    "\n",
    "epochs_range = range(1, len(train_loss_values) + 1)\n",
    "\n",
    "best_learning_curves_df = pd.DataFrame({\n",
    "    \"Epoch\": range(1, len(train_loss_values) + 1),\n",
    "    \"Training Loss\": train_loss_values,\n",
    "    \"Validation Loss\": val_loss_values\n",
    "})\n",
    "\n",
    "# Set default font type and sizes\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'DejaVu Sans',\n",
    "    'font.size': 8.5,             \n",
    "    'axes.labelsize': 8.5,         \n",
    "    'axes.titlesize': 8.5,        \n",
    "    'legend.fontsize': 8.5,        \n",
    "    'xtick.labelsize': 8.5,        \n",
    "    'ytick.labelsize': 8.5         \n",
    "})\n",
    "\n",
    "# Set figure size\n",
    "fig_curves, ax_curves = plt.subplots(figsize=((10 / cm_to_inch, 6 / cm_to_inch)))\n",
    "\n",
    "# Plotting the loss values\n",
    "ax_curves.plot(epochs_range, train_loss_values, label='Training Loss')\n",
    "ax_curves.plot(epochs_range, val_loss_values, label='Validation Loss')\n",
    "ax_curves.set_xlabel('Epochs [-]')  # Font size set globally\n",
    "ax_curves.set_ylabel('Loss [-]')     # Font size set globally\n",
    "ax_curves.set_title('Training and Validation Loss Over the Epochs')  # Font size set globally\n",
    "ax_curves.legend()          # Font size set globally\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1539,
     "status": "ok",
     "timestamp": 1730142470120,
     "user": {
      "displayName": "Máté Seidl",
      "userId": "15686571343071383312"
     },
     "user_tz": -60
    },
    "id": "-QTQgZS-bwKj",
    "outputId": "3ba0ee83-6cb7-4e36-9b62-e578160e66ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "\n",
    "# define connector type\n",
    "if dataset_id == 0:\n",
    "    connector_type = \"ethernet\"\n",
    "elif dataset_id == 2:\n",
    "    connector_type = \"hva280\"\n",
    "elif dataset_id == 4:\n",
    "    connector_type = \"hva630\"\n",
    "\n",
    "cwd = str(Path.cwd())\n",
    "\n",
    "if system == \"Linux\" and local_system == False:\n",
    "    models_dir = \"drive/MyDrive/Masters_thesis_clickSense/03_Click_Detection_Model/02_savedWeights\"\n",
    "    models_dir_path = os.path.join(cwd, models_dir)\n",
    "elif system == \"Linux\" and local_system == True:\n",
    "    models_dir = \"02_savedWeights\"\n",
    "    models_dir_path = os.path.join(cwd, models_dir)\n",
    "elif system == \"Darwin\":\n",
    "    models_dir = \"02_savedWeights\"\n",
    "    models_dir_path = os.path.join(cwd, models_dir)\n",
    "\n",
    "if not os.path.exists(models_dir_path):\n",
    "    os.makedirs(models_dir_path)\n",
    "\n",
    "# chek if there any model in the directory\n",
    "model_files = [f for f in os.listdir(models_dir_path) if f.endswith('.pt')]\n",
    "\n",
    "# sorting function for files\n",
    "def sort_key_func(file_name):\n",
    "        #numbers = re.findall(r'\\d+', file_name)\n",
    "        number = file_name.split('_')[3]\n",
    "        if number:\n",
    "            return int(number) if number.isdigit() else -1\n",
    "            #return int(number) # return the last number in file name\n",
    "        return file_name\n",
    "\n",
    "def extract_model_number(file_name):\n",
    "    try:\n",
    "        #return int(file_name.split('_')[-1].split('.')[0])\n",
    "        number = file_name.split('_')[3]\n",
    "        if number:\n",
    "            return int(number) if number.isdigit() else -1\n",
    "            #return int(number) # return the last number in file name\n",
    "    except ValueError:\n",
    "        print(\"Latest model number could not be extracted\")\n",
    "\n",
    "connector_model_files = []\n",
    "for i in model_files:\n",
    "    if connector_type in i:\n",
    "        connector_model_files.append(i)\n",
    "print(len(connector_model_files))\n",
    "\n",
    "# create file name with the highest number after the model_ prefix\n",
    "if len(connector_model_files) == 0:\n",
    "    highest_model_number = -1\n",
    "else:\n",
    "    connector_model_files.sort(key=sort_key_func)\n",
    "    highest_model_number = extract_model_number(connector_model_files[-1])\n",
    "\n",
    "model_file_name = f\"{connector_type}_det_model_run{highest_model_number + 1}_ch1{best_training_params[0]}_ch2{best_training_params[1]}.pt\" # connector type + channel size 1 and channel size 2\n",
    "confusion_matrix_file_name = f\"{connector_type}_det_model_run{highest_model_number + 1}_ch1{best_training_params[0]}_ch2{best_training_params[1]}_confusion_matrix.png\"\n",
    "learning_curves_file_name = f\"{connector_type}_det_model_run{highest_model_number + 1}_ch1{best_training_params[0]}_ch2{best_training_params[1]}_lr{best_training_params[2]}_learning_curves.pdf\"\n",
    "learning_curves_file_name_csv = f\"{connector_type}_det_model_run{highest_model_number + 1}_ch1{best_training_params[0]}_ch2{best_training_params[1]}_lr{best_training_params[2]}_learning_curves.csv\"\n",
    "\n",
    "model_file_path = os.path.join(models_dir_path, model_file_name)\n",
    "torch.save(best_model_weights, model_file_path) # only saving the state_dict() only saves the learned parameters\n",
    "\n",
    "# save the results\n",
    "if local_system == False:\n",
    "    save_dir_training_results = \"/content/drive/MyDrive/Masters_thesis_clickSense/03_Click_Detection_Model/03_trainingResults\"\n",
    "else:\n",
    "    cwd = str(Path.cwd())\n",
    "    save_dir_training_results = os.path.join(cwd, \"03_trainingResults\")\n",
    "\n",
    "os.makedirs(save_dir_training_results, exist_ok=True)\n",
    "\n",
    "save_path_confusion_matrix = os.path.join(save_dir_training_results, confusion_matrix_file_name)\n",
    "save_path_learning_curves = os.path.join(save_dir_training_results, learning_curves_file_name)\n",
    "save_path_learning_curves_csv = os.path.join(save_dir_training_results, learning_curves_file_name_csv)\n",
    "\n",
    "fig_cm.savefig(save_path_confusion_matrix, format=\"png\", dpi=200, bbox_inches=\"tight\")\n",
    "fig_curves.savefig(save_path_learning_curves, format=\"pdf\", bbox_inches=\"tight\")\n",
    "best_learning_curves_df.to_csv(save_path_learning_curves_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIiNVDABbwKk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "clickSense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "483936814556495094d617bdc33d2b6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50691ce548d945a0861e34543806595e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53eecbecb7d74bb08fbd26a13d2039a8",
       "IPY_MODEL_f1e855ac80a54fd3bb932daeff22a824",
       "IPY_MODEL_fd7e8de4a8ec4a54bd8dccb087585df1"
      ],
      "layout": "IPY_MODEL_cf4a2e8addf94787b6a90d7afaab92ab"
     }
    },
    "53eecbecb7d74bb08fbd26a13d2039a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58e5b7754d35431a96eef108f38f524a",
      "placeholder": "​",
      "style": "IPY_MODEL_583588cc9b384f35a48f2928835940c1",
      "value": " 47%"
     }
    },
    "583588cc9b384f35a48f2928835940c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58e5b7754d35431a96eef108f38f524a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65222142ffde4598b27256090659c53d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b56246ce756499bbd82393aa8323f3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf4a2e8addf94787b6a90d7afaab92ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e84ee5d377104ce7ac52341ebaf1866b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f1e855ac80a54fd3bb932daeff22a824": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_483936814556495094d617bdc33d2b6f",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e84ee5d377104ce7ac52341ebaf1866b",
      "value": 14
     }
    },
    "fd7e8de4a8ec4a54bd8dccb087585df1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b56246ce756499bbd82393aa8323f3b",
      "placeholder": "​",
      "style": "IPY_MODEL_65222142ffde4598b27256090659c53d",
      "value": " 14/30 [02:01&lt;02:09,  8.12s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
